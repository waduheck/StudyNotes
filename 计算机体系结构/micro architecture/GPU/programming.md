![[Pasted image 20231226102947.png]]

![[Pasted image 20231226092128.png]]
![[Pasted image 20231226092226.png]]
![[Pasted image 20231226092504.png]]

![[Pasted image 20231226092607.png]]

![[Pasted image 20231226093359.png]]

![[Pasted image 20231226100621.png]]

![[Pasted image 20231226100822.png]]

![[Pasted image 20231226100952.png]]

## 几种gpu架构
![[Pasted image 20231226101353.png]]
![[Pasted image 20231226101426.png]]
![[Pasted image 20231226101445.png]]

## memory access
### latency hiding
![[Pasted image 20231226101808.png]]

### 内存合并
**目的**：

- 当访问全局内存时，我们希望确保并行运行的线程访问临近的内存位置。这样可以最大化带宽利用率，因为物理内存的读写通常是以缓存行为单位进行的。

**优化**：

- 如果一个线程束（在CUDA中称为“warp”，通常包含32个线程）中的所有线程同时访问一个缓存行内的数据，则可以一次性通过一个内存事务来满足所有线程的数据需求。

**合并访问**：

- 合并访问（Coalesced Access）意味着线程束中的线程访问连续的内存地址，这样它们就能共享同一个内存读写事务。
![[Pasted image 20231226102620.png]]
![[Pasted image 20231226102633.png]]
![[Pasted image 20231226102831.png]]

## data reuse
### sharing memory —— tiling
![[Pasted image 20231226103722.png]]
这张PPT幻灯片讨论了在GPU编程中使用的一个性能优化技术——平铺（Tiling）。这种技术通常用于提高数据在共享内存中的重用率，进而提高GPU内核的执行效率。

#### 平铺（Tiling）概念：

**目的**：
- 平铺是一种将输入数据分割成较小的块（称为“瓷砖”或“tiles”）的方法，这样这些块就可以被加载进GPU的共享内存中。
- 共享内存是GPU上各个线程块（thread blocks）之间可共享的快速内存区域，比全局内存具有更低的访问延迟和更高的带宽。

**优势**：
- 通过将数据分割成tiles并加载到共享内存中，可以减少访问全局内存的次数，因为同一个tile中的数据可以被同一个线程块中的多个线程重复使用。

#### 幻灯片上的代码和图示：

- 代码展示了如何在CUDA C中声明共享内存数组（使用`__shared__`关键字），并如何将数据加载到这个数组中。
- 图示展示了一个大的数据矩阵，其中高亮显示的部分代表一个被加载到共享内存的tile。
- 在代码中，`syncthreads()`是一个同步原语，用于确保线程块中的所有线程都在继续执行之前完成了对共享内存的加载操作。
- 然后，代码中的双层循环用于在某个运算（可能是卷积或矩阵操作）中使用tile中的数据。这个运算中的`sum`变量累加了一个3x3邻域内的数据与另一个数组（`gauss`）中值的乘积。

#### 重要性：

在GPU编程中，全局内存的访问通常是最大的性能瓶颈之一。平铺技术允许程序员显著减少全局内存的访问次数，因为一次从全局内存到共享内存的数据传输可以服务于多个后续的内存访问操作。通过高效地使用共享内存，程序员可以优化GPU内核的性能，提高数据吞吐量，从而加速整个程序的执行。

### sharing memory bank conflict
根据鸽巢原理，当往较小的存储元素中塞入大量线程时会导致conflict
![[Pasted image 20231226104259.png]]
![[Pasted image 20231226104217.png]]

![[Pasted image 20231226104926.png]]
![[Pasted image 20231226104916.png]]
这两张PPT幻灯片讲述的是在GPU编程中处理并行数据时的两种不同的映射策略。
### 第一张幻灯片：Vector Reduction: Naïve Mapping

这张幻灯片展示了一种向量归约操作的简单映射策略。向量归约是将所有元素的操作合并成一个单一结果的过程，如加和。

**关键点**：
- **简单映射**（Naïve Mapping）可能会导致效率低下，因为它没有考虑到内存访问模式，可能会造成内存访问分歧或非合并访问。
- 在这个例子中，每个线程计算两个元素的和，然后迭代减少直到得到最终结果。每一步中的线程数减半，并且每个线程都合并前一步的结果。
- 这种策略可能在初期步骤中不高效，因为它没有利用所有的线程，也可能因为内存访问模式不是合并的而导致内存带宽没有得到充分利用。
### 第二张幻灯片：Divergence-Free Mapping

这张幻灯片展示了一种确保所有激活线程都属于同一个线程束（warp）的内存访问策略。在GPU中，一个warp是一组同时执行相同指令的线程。

**关键点**：
- **无分歧映射**（Divergence-Free Mapping）意味着所有线程在每一步中都执行相同的操作，没有条件分支导致的线程分歧。
- 这种映射策略通过让一个warp中的所有线程访问连续的内存地址来实现，这样可以提高内存访问效率，并确保最大化内存带宽利用率。
- 例如，在迭代操作中，每个线程可以按照顺序处理一个数据块，如数组中的元素，这些元素被连续地映射到每个线程。



### 总结

两张幻灯片都是关于GPU编程中如何有效地组织线程以优化内存访问的。第一张强调了无分歧映射，目的是确保线程束中的线程能够以最高效率访问内存。第二张讨论了向量归约的一种简单实现，展示了在多个线程协同工作下如何逐步合并结果。在实际应用中，开发者需要根据具体情况选择最适合的映射和归约策略，以确保高性能和有效的资源利用。

### sharing memory ： atomic conflict
"原子的"（atomic）在计算机科学中通常指一个操作是不可分割的，即在执行完整个操作之前，它不会被任何其他操作打断。在多线程环境中，原子操作对于同步共享资源的访问非常重要，因为它们帮助防止并发执行时的数据竞争和不一致。

![[Pasted image 20231226112545.png]]
- **输入数据**：
  - 图示显示了图像数据分布在多个线程之间。每个线程处理输入数据的不同部分。

- **线程**：
  - 每个线程读取其分配的数据并尝试更新共享的直方图结构。

- **直方图**：
  - 直方图的bins由多个线程更新，其中每个bin对应一个特定的像素值范围。

### 解决方案：

- 在实际应用中，为了安全地更新直方图，可能需要使用原子操作（如前一张PPT中讲到的`atomicAdd`），或者每个线程使用自己的局部直方图副本，最后再将所有局部直方图合并到一个全局直方图中。

然而过多的a to
![[Pasted image 20231226112605.png]]





![[Pasted image 20231226102947.png]]

![[Pasted image 20231226092128.png]]
![[Pasted image 20231226092226.png]]
![[Pasted image 20231226092504.png]]

![[Pasted image 20231226092607.png]]

![[Pasted image 20231226093359.png]]

![[Pasted image 20231226100621.png]]

![[Pasted image 20231226100822.png]]

![[Pasted image 20231226100952.png]]

## 几种gpu架构
![[Pasted image 20231226101353.png]]
![[Pasted image 20231226101426.png]]
![[Pasted image 20231226101445.png]]

## memory access
### latency hiding
![[Pasted image 20231226101808.png]]

### 内存合并
**目的**：

- 当访问全局内存时，我们希望确保并行运行的线程访问临近的内存位置。这样可以最大化带宽利用率，因为物理内存的读写通常是以缓存行为单位进行的。

**优化**：

- 如果一个线程束（在CUDA中称为“warp”，通常包含32个线程）中的所有线程同时访问一个缓存行内的数据，则可以一次性通过一个内存事务来满足所有线程的数据需求。

**合并访问**：

- 合并访问（Coalesced Access）意味着线程束中的线程访问连续的内存地址，这样它们就能共享同一个内存读写事务。
![[Pasted image 20231226102620.png]]
![[Pasted image 20231226102633.png]]
![[Pasted image 20231226102831.png]]

## data reuse
### sharing memory —— tiling
![[Pasted image 20231226103722.png]]
这张PPT幻灯片讨论了在GPU编程中使用的一个性能优化技术——平铺（Tiling）。这种技术通常用于提高数据在共享内存中的重用率，进而提高GPU内核的执行效率。

#### 平铺（Tiling）概念：

**目的**：
- 平铺是一种将输入数据分割成较小的块（称为“瓷砖”或“tiles”）的方法，这样这些块就可以被加载进GPU的共享内存中。
- 共享内存是GPU上各个线程块（thread blocks）之间可共享的快速内存区域，比全局内存具有更低的访问延迟和更高的带宽。

**优势**：
- 通过将数据分割成tiles并加载到共享内存中，可以减少访问全局内存的次数，因为同一个tile中的数据可以被同一个线程块中的多个线程重复使用。

#### 幻灯片上的代码和图示：

- 代码展示了如何在CUDA C中声明共享内存数组（使用`__shared__`关键字），并如何将数据加载到这个数组中。
- 图示展示了一个大的数据矩阵，其中高亮显示的部分代表一个被加载到共享内存的tile。
- 在代码中，`syncthreads()`是一个同步原语，用于确保线程块中的所有线程都在继续执行之前完成了对共享内存的加载操作。
- 然后，代码中的双层循环用于在某个运算（可能是卷积或矩阵操作）中使用tile中的数据。这个运算中的`sum`变量累加了一个3x3邻域内的数据与另一个数组（`gauss`）中值的乘积。

#### 重要性：

在GPU编程中，全局内存的访问通常是最大的性能瓶颈之一。平铺技术允许程序员显著减少全局内存的访问次数，因为一次从全局内存到共享内存的数据传输可以服务于多个后续的内存访问操作。通过高效地使用共享内存，程序员可以优化GPU内核的性能，提高数据吞吐量，从而加速整个程序的执行。

### sharing memory bank conflict
根据鸽巢原理，当往较小的存储元素中塞入大量线程时会导致conflict
![[Pasted image 20231226104217.png]]
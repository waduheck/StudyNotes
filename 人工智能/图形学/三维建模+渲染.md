3D数据的不同表示类型:深度图(depth), 点云(point cloud), 体素(voxel), 网格(mesh)。

几种渲染方法：光线追踪（Ray casting）、光栅化
## 体素插值法
一般情况下，我们需要查询的点，并不会和grid的顶点重合。所以查询的时候，需要先找到采样点在哪个小立方体内，然后再对立方体的八个顶点做插值来求解
## spatial hash function

## Voxel Hashing

![[八叉树.png]]

![[voxel hash.png]]

http://liuxiao.org/kb/3dvision/3d-reconstruction/voxel-hashing/
## Neural Radiance Caching
https://blog.csdn.net/qq_42537915/article/details/123139515  

Neural Radiance Caching 是一种用于提高光线追踪渲染速度的技术，它结合了传统的辐射度缓存（Radiance Caching）方法和神经网络的能力。这种方法特别适用于全局光照计算，这是一个计算密集型的任务，因为它涉及到模拟光如何在场景中多次反射和散射。

在传统的辐射度缓存中，算法会在场景中的关键位置存储间接光照的结果，这样在渲染过程中就可以重用这些结果而不是每次都重新计算光照。这大大提高了渲染速度，但是它也有可能导致错误，特别是在缓存的样本之间插值时。

Neural Radiance Caching 的工作原理如下：

1. **数据采集**：
   - 通过光线追踪过程，收集光照样本，包括光线的方向、颜色、亮度等。

2. **神经网络训练**：
   - 使用采集到的数据来训练一个神经网络，让它学习预测场景中任何给定位置的辐射度（光照信息）。

3. **辐射度估计**：
   - 在渲染过程中，使用训练好的神经网络来快速估计间接光照，而不是从头开始计算。

4. **缓存和重用**：
   - 存储神经网络的输出以便重用，并在需要时对其进行更新。

Neural Radiance Caching 的主要优点是能够更准确地插值间接光照，减少了传统方法中的伪影（如光斑或不连续性）。由于神经网络可以捕获场景的复杂光照分布，因此它能够在样本之间进行更平滑和更准确的插值。

此技术是近年来为了解决全局光照计算中的效率和质量问题而发展起来的，它是计算机图形学中许多尝试结合传统图形算法和深度学习技术的研究工作之一。通过这种结合，渲染器能够以更高的速度产生接近真实的图像，特别是在实时渲染领域，这是一个重要的研究方向。
## SDF（有符号距离场）
https://zhuanlan.zhihu.com/p/337944099
生成符号距离函数（Signed Distance Function, SDF）的算法可以从不同的角度进行分类。以下是几种常见的方法：

1. **解析方法**:
   - 对于简单的几何形状（如球体、立方体、圆柱体等），可以直接使用解析公式来计算任意点到这些形状表面的最短距离。

2. **网格转换方法**:
   - **点云到SDF**: 当有一个点云表示的形状时，可以通过估计点云中每个点到最近表面的距离来构建SDF。
   - **三角网格到SDF**: 对于三角网格模型，可以使用距离场算法来计算网格表面上每个点的SDF值。

3. **体素化方法**:
   - 通过将空间划分为规则的网格（体素），并对每个体素中的点计算其到最近表面的距离来构建SDF。

4. **光线投射法**:
   - 通过从多个方向对物体进行光线投射，并记录光线与物体表面的交点信息来生成SDF。

5. **基于图像的方法**:
   - 使用从多个角度拍摄的图像，通过光线跟踪或立体视觉算法来估算SDF。

6. **快速行进方法（Fast Marching Method, FMM）**:
   - 一种数值方法，适用于计算静态Hamilton-Jacobi方程的解，可以用来构建SDF。

7. **优化方法**:
   - 通过优化技术，比如变分方法，来逼近点云或网格数据的SDF。

8. **机器学习方法**:
   - 利用深度学习，尤其是卷积神经网络（CNNs），来从复杂的三维数据中直接学习SDF。

9. **距离变换（Distance Transform）**:
   - 在图像处理中，距离变换可用于计算二维图像中每个像素到最近边缘的距离，这可以扩展到三维来生成SDF。

每种方法都有其优势和局限性，选择哪一种取决于具体的应用场景和可用数据。例如，解析方法在精度和计算速度上表现出色，但仅限于简单几何体；而机器学习方法则适用于复杂的形状，但需要大量的训练数据和计算资源。在实际应用中，这些方法有时会被组合使用，以利用各自的优势。

## SFM

## MVS

## 光线追踪
![[ray casting.png]]
一条射线可以用公式$r(t)=o+td$ 表示，其中$o$是原点坐标，$d$是方向向量
### 可微分渲染器
#### 立体渲染（volume rendering）
https://zhuanlan.zhihu.com/p/595117334
![[体渲染.webp]]
##### 吸收absorbing
![[体渲染吸收.webp]]
$$\frac{dI}{ds}=-\rho(s)AI(s)=-\tau_aI(s)$$
解微分方程得$$I(s)=I_0exp(-\int_0^s\tau_a(t)dt)$$
##### 放射emission
假设单个粒子发射的一束光辐射强度为$I_e$
$$\frac{dI}{ds}=I_e(s)\rho(s)A=I_e(s)\tau_a(s)$$
##### 外散射out-scattering
我们用$\tau_s$来表示外散射对光线的削弱比例
$$\frac{dI}{ds}=-\tau_s(s)I(s)$$

##### 内散射in-scattering
我们认为其他光路的辐射强度是$I_s$
$$\frac{dI}{ds}=-\tau_s(s)I_s(s)$$
##### 体渲染方程
###### 连续
将上述四个过程综合起来可以得到
$$\frac{dI}{ds} = -\tau_a(s)I(s)-\tau_s(s)I(s)+\tau_a(s)I_e(s)+\tau_s(s)I_s(s)$$
其中，**吸收**和**外散射**都会削弱光线的辐射强度，并且由于它们都和入射光有关，因此它们共同构成了体渲染中的**衰减项 (attenuation item)，而粒子发光**和**内散射**都来自独立的光源，因此被称为**源项 (source item)**。
为了求解方便，定义$\tau_t = \tau_a + \tau_s$,于是
$$I(s)=\int_0^sexp(-\int_0^t\tau_t(u)du)[\tau_a(t)I_e(t)+\tau_s(t)I_s(t)dt]+I_0exp(-\int_0^s\tau_t(t)dt)$$
我们进一步大胆假设:**$\tau_t,\tau_a,\tau_s$这些都相等，统一用$\sigma$表示,同时令$C=I_e +I_s$**
$$I(s)=\int_0^sT(t)\sigma(t)C(t)dt+T(s)I_0$$
其中$T(s)=exp(-\int_0^s\sigma(t)dt)$
我们再做简化，忽略背景光一项，即可获得nerf公式
$$C(r)=\int_{t_n}^{t_f}T(t)\sigma(r(t))c(r(t),d)dt, \quad where T(t) = exp(-\int_{t_n}^t\sigma(r(s))ds)$$
###### 离散
计算机中无法直接计算积分，我们需要将其离散化，将光路$[0,s]$,划分为N个等间距的区间:$[t_n,t_{n+1}]$,为了简化计算，我们假设每个区间内，$\sigma(t)处处等于\sigma_n,C(t)处处等于C_n$
$$那么I(t_n\rightarrow t_{n+1})=\sigma_nC_n\int_{t_n}^{t_{n+1}}T(t)dt$$
$$其中T(t)=exp(-\int_0^{t_n}\sigma(u)du)exp(-\int_{t_n}^{t}\sigma(u)du)=T(0\rightarrow t_n)T(t_n \rightarrow t)$$
将其带回原式子，运算得$$$$那么$$I(t_n\rightarrow t_{n+1})=T(0 \rightarrow t_n)C_n(1-exp(-\sigma_n(t_{n+1 - t_n})))$$
接下来累加每一段$I(t_n\rightarrow t_{n+1})$,并且离散化$T(0\rightarrow t_n)$
过程查看 https://zhuanlan.zhihu.com/p/595117334
结果$$\hat C(r) = \sum_{i=1}^NT_i(1-exp(-\sigma_i\theta_i))c_i,\quad where\quad T=exp(-\sum_{j=1}^{i-1}\sigma_j\theta_j)$$
## 图像顺序法和对象顺序法
体绘制技术可分为图像顺序法和对象顺序法。

图像排序方法：

在二维图像空间中工作-图像平面上的像素作为体积遍历的起点。从像素开始，遍历数据量。

例如光线投射法，从屏幕发出光线，采集数据场。

对象排序方法：

遵循一定的组织方式来扫描对象空间中的三维体。然后将遍历的体积区域投影到图像平面上。

例如Texture-sliced方法，把体数据排列在GPU中，然后合成。

## 高斯splatting 
https://www.bilibili.com/video/av872162410/?vd_source=0c5ad79582f906d810296380161a7988

## cubemap
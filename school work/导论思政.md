## gaussian splatting与nerf——新视角合成新范式


传统新视角合成
最初的新视角合成方法基于光场技术，起初是密集采样，后来允许非结构化捕获。结构从运动（SfM）的出现使得使用一系列照片来合成新视角成为可能。SfM在相机校准期间估计一个稀疏点云，最初用于简单的3D空间可视化。随后的多视图立体视觉（MVS）在多年间产生了令人印象深刻的完整3D重建算法，促进了多种视角合成算法的发展。所有这些方法都将输入图像重新投影并混合到新视角相机中，并使用几何信息来引导这种重新投影。这些方法在许多情况下都取得了优秀的结果，但通常无法完全从未重建区域或“过度重建”中恢复，即MVS生成不存在的几何结构。最新的神经渲染算法大大减少了这类伪影，并避免了在GPU上存储所有输入图像的巨大成本，在大多数方面都优于这些方法。

ai新视角合成
最初，卷积神经网络（CNNs）被用于估计混合权重或处理纹理空间解决方案。这些方法的主要缺点是依赖基于多视图立体视觉（MVS）的几何结构，且使用CNN进行最终渲染常导致时间上的闪烁。之后，提出了结合深度学习技术的体积表示方法，以连续可微的密度场表示几何结构。然而，传统的体积光线追踪渲染方式由于需要查询大量样本而成本较高。NeRF通过引入重要性采样和位置编码来提高质量，但使用大型多层感知机（MLP），影响了速度。最新的方法着重于通过使用空间数据结构、不同编码和MLP容量来加快训练和/或渲染速度。这些方法包括空间离散化、代码本和编码（如哈希表），允许使用更小的MLP或完全不使用神经网络。最值得注意的方法包括InstantNGP和Plenoxels，它们分别使用哈希网格和稀疏体素网格加速计算，并能够不使用神经网络。尽管这些方法取得了杰出的成果，但在有效表示空间方面仍存在挑战，并且图像质量在很大程度上受到用于加速的结构化网格的选择限制，渲染速度也受到光线追踪步骤中需要查询多个样本的影响。而作者使用的非结构化、显式的GPU友好的3D高斯方法实现了更快的渲染速度和更好的质量，而无需神经组件。

（上面两个来自于gaussian splatting 2.1 2.2 2.3）

text-2-3d
文本到3D生成旨在从文本提示生成3D素材。最近，基于数据驱动的2D扩散模型在文本到图像生成方面取得了显著成就。然而，将其转移到3D生成上并非易事，因为策划大规模3D数据集具有挑战性。现有的3D原生扩散模型通常只针对单一物体类别，且多样性有限。为了实现开放词汇的3D生成，一些方法提出将2D图像模型用于3D生成。这些2D提升方法通过优化3D表示，以确保在不同视角渲染时在预训练的2D扩散模型中获得高概率，从而确保3D一致性和真实感。后续工作继续增强生成保真度和训练稳定性，并探索进一步应用。然而，这些基于优化的2D提升方法通常存在长时间的逐例优化问题。特别是，使用NeRF作为3D表示会在前向和后向过程中导致昂贵的计算。在这项工作中，我们选择3D高斯作为可微分的3D表示，并从经验上展示它具有更简单的优化景观。
（来自dream gaussian）

image-2-3d



（来自zero 123）


3d editting 
编辑神经场由于其形状和外观之间的复杂相互作用而具有挑战性。EditNeRF 在这一领域开创了先河，它通过对神经场使用潜在代码来编辑形状和颜色。此外，一些工作利用CLIP模型通过文本提示或参考图像来便于编辑。另一方面的研究聚焦于使用预定义的模板模型或骨架来支持特定类别内的重新定位或重新渲染。基于几何的方法将神经场转换为网格，并与隐式场同步网格变形。此外，3D编辑技术涉及将2D图像操作（如修复）与神经场训练结合起来。同时，一些工作利用静态2D和3D遮罩来限制NeRF的编辑区域。然而，这些方法有其局限性，因为3D模型的训练是一个动态过程，静态遮罩无法有效地限制它。与此相反，我们的研究采用高斯语义追踪在整个训练过程中追踪目标高斯。
（来自gaussian editor）

动态3维重建




